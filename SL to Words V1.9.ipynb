{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392719d6",
   "metadata": {},
   "source": [
    " # Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b11df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T09:05:52.519770Z",
     "start_time": "2022-03-03T09:05:50.859095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fdd3d6",
   "metadata": {},
   "source": [
    " # Keypoints using Mediapipe Holistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c85a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T09:05:53.659382Z",
     "start_time": "2022-03-03T09:05:53.641352Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2225e256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T09:05:54.530280Z",
     "start_time": "2022-03-03T09:05:54.514236Z"
    }
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(frame, model):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Model (Holistic) works on RGB not BGR\n",
    "    frame.flags.writeable = False # To improve performance, optionally mark the image as not writeable to pass by reference\n",
    "    results = model.process(frame)                 # Make prediction\n",
    "    frame.flags.writeable = True\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    return frame, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fe9bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T09:05:55.694842Z",
     "start_time": "2022-03-03T09:05:55.676825Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_landmarks(frame, model): # BGR\n",
    "    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80, 200, 100), thickness=2, circle_radius=3),  # Points\n",
    "                             mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2) # Connection\n",
    "                             ) \n",
    "    mp_drawing.draw_landmarks(frame, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=1, circle_radius=1),     \n",
    "                             mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=1, circle_radius=1)  \n",
    "                             )   \n",
    "    mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2)\n",
    "                             )    \n",
    "    mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2)\n",
    "                             )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f225bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T09:06:02.607364Z",
     "start_time": "2022-03-03T09:06:02.587385Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark[11:15]]).flatten() if results.pose_landmarks else np.zeros(8)\n",
    "    face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(936)\n",
    "    lefthand = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(42)\n",
    "    righthand = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(42)\n",
    "    return np.concatenate([pose, face, lefthand, righthand])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9a3ea",
   "metadata": {},
   "source": [
    " # Get Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eed426d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T09:06:05.326772Z",
     "start_time": "2022-03-03T09:06:05.319810Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDistance(frame, results):\n",
    "    h, w, c = frame.shape\n",
    "    distance = int(math.sqrt((results.pose_landmarks.landmark[8].y * h - results.pose_landmarks.landmark[7].y * h)**2 + (results.pose_landmarks.landmark[8].x * w - results.pose_landmarks.landmark[7].x * w)**2)) if results.pose_landmarks else 0\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0eb63e",
   "metadata": {},
   "source": [
    " # For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f148a22",
   "metadata": {},
   "source": [
    " # Create Folders for Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ca218da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T15:07:48.718253Z",
     "start_time": "2022-03-03T15:07:48.693294Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('Data')\n",
    "\n",
    "actions = np.array(['باذنجان'])  # Words\n",
    "\n",
    "no_videos = 30 # 30\n",
    "\n",
    "video_length = 30  # Video is 30 frames in length\n",
    "\n",
    "for action in actions:\n",
    "    for video in range(no_videos):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(video)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53beede",
   "metadata": {},
   "source": [
    " # Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56856761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T15:08:49.307403Z",
     "start_time": "2022-03-03T15:07:51.697730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "طعمية\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "with mp_holistic.Holistic() as holistic:\n",
    "   \n",
    "    for action in actions:\n",
    "        print(action)\n",
    "        for video in range(no_videos):\n",
    "            for frame_num in range(video_length):       \n",
    "                ret, frame = cap.read()\n",
    "                if ret == False:\n",
    "                    break\n",
    "            \n",
    "                # Wait between each video\n",
    "                if frame_num == 0:                    \n",
    "                    cv2.waitKey(2000)\n",
    "                    \n",
    "                frame, results = mediapipe_detection(frame, holistic)\n",
    "                draw_landmarks(frame, results)\n",
    "                   \n",
    "                # FLip frame\n",
    "                frame = cv2.flip(frame,1)\n",
    "\n",
    "                # Distance\n",
    "                distance = getDistance(frame, results)\n",
    "                cv2.putText(frame, f'Distance {distance}', (530,20),\\\n",
    "                                    cv2.FONT_ITALIC, 0.5, (0,0,255), 2)\n",
    "                    \n",
    "                # Video Number\n",
    "                cv2.putText(frame, f'{action} video number {video}', (15,20),\\\n",
    "                            cv2.FONT_ITALIC, 0.5, (0,0,255), 2)\n",
    "                    \n",
    "                # Export Keypoints (Save as numpy)\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(video), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                \n",
    "                cv2.imshow('Esm3ni', frame)\n",
    "        \n",
    "                # Pause\n",
    "                if key == 32:\n",
    "                    cv2.waitKey(7000)\n",
    "                    print('redy')\n",
    "                    cv2.waitKey(3000)\n",
    "            \n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27:\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows() \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5edeb",
   "metadata": {},
   "source": [
    " ### Test before creating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c59d7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T14:59:06.890963Z",
     "start_time": "2022-03-03T14:58:30.602722Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "with mp_holistic.Holistic() as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        frame, results = mediapipe_detection(frame, holistic)\n",
    "        # print(results)  # <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_landmarks(frame, results)\n",
    "        \n",
    "        # FLip frame\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # Distance\n",
    "        distance = getDistance(frame, results)\n",
    "        cv2.putText(frame, f'Distance {distance}', (530,20),\\\n",
    "                            cv2.FONT_ITALIC, 0.5, (0,0,255), 2)\n",
    "        \n",
    "        cv2.imshow('Esm3ni', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)       \n",
    "        # Pause\n",
    "        if key == 32:\n",
    "            input()\n",
    "            cv2.waitKey(2000)\n",
    "        \n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "99231431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T16:33:47.812783Z",
     "start_time": "2022-02-26T16:33:47.791783Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8cd28",
   "metadata": {},
   "source": [
    " # Works on DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6227217b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:42:54.388298Z",
     "start_time": "2022-03-03T08:42:22.054474Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98dff5cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:42:54.435981Z",
     "start_time": "2022-03-03T08:42:54.422987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['اناناس', 'برتقان', 'بطيخ', 'بلح', 'تفاح', 'عنب', 'فراولة'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join('Data')\n",
    "no_videos = 30\n",
    "video_length = 30\n",
    "\n",
    "actions = np.array(os.listdir(DATA_PATH))\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4624ba40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:43:13.163139Z",
     "start_time": "2022-03-03T08:43:13.150147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'اناناس': 0,\n",
       " 'برتقان': 1,\n",
       " 'بطيخ': 2,\n",
       " 'بلح': 3,\n",
       " 'تفاح': 4,\n",
       " 'عنب': 5,\n",
       " 'فراولة': 6}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_map = {action: idd for idd, action in enumerate(actions)}\n",
    "action_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08882d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:27.940844Z",
     "start_time": "2022-03-03T08:43:16.109073Z"
    }
   },
   "outputs": [],
   "source": [
    "videos, labels = [], []\n",
    "for action in actions:\n",
    "    for video in range(no_videos):\n",
    "        temp = []\n",
    "        for frame_num in range(video_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(video), f'{frame_num}.npy'))\n",
    "            temp.append(res)\n",
    "        videos.append(temp)\n",
    "        labels.append(action_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "917c26be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:31.078038Z",
     "start_time": "2022-03-03T08:44:30.988715Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array(videos)\n",
    "y = to_categorical(labels, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b86fb0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:34.730280Z",
     "start_time": "2022-03-03T08:44:34.643243Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7604a",
   "metadata": {},
   "source": [
    " # NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf6658c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:37.143684Z",
     "start_time": "2022-03-03T08:44:37.131688Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77c46e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:39.719520Z",
     "start_time": "2022-03-03T08:44:38.729683Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(30, 1028)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax')) # sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ffe3221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:42.171387Z",
     "start_time": "2022-03-03T08:44:42.141422Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f976a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:44:54.759258Z",
     "start_time": "2022-03-03T08:44:48.843313Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 16ms/step - loss: 3.1563 - categorical_accuracy: 0.1530\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.8319 - categorical_accuracy: 0.2089\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.2935 - categorical_accuracy: 0.2810\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0054 - categorical_accuracy: 0.1513\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6327 - categorical_accuracy: 0.3302\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6052 - categorical_accuracy: 0.3966\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3026 - categorical_accuracy: 0.4633\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1916 - categorical_accuracy: 0.5165\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0149 - categorical_accuracy: 0.6110\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0307 - categorical_accuracy: 0.5630\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0229 - categorical_accuracy: 0.7232\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9547 - categorical_accuracy: 0.7462\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8952 - categorical_accuracy: 0.6823\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8217 - categorical_accuracy: 0.7891\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7537 - categorical_accuracy: 0.7835\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6938 - categorical_accuracy: 0.8098\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7199 - categorical_accuracy: 0.6790\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7070 - categorical_accuracy: 0.7432\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6231 - categorical_accuracy: 0.7861\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5704 - categorical_accuracy: 0.8186\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5118 - categorical_accuracy: 0.9001\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5363 - categorical_accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4659 - categorical_accuracy: 0.8260\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4263 - categorical_accuracy: 0.8470\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5296 - categorical_accuracy: 0.7969\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4173 - categorical_accuracy: 0.8731\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4093 - categorical_accuracy: 0.8259\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4024 - categorical_accuracy: 0.8114\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3596 - categorical_accuracy: 0.8918\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3420 - categorical_accuracy: 0.8376\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2493 - categorical_accuracy: 0.9508\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2704 - categorical_accuracy: 0.8837\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2639 - categorical_accuracy: 0.8838\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2740 - categorical_accuracy: 0.8754\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2175 - categorical_accuracy: 0.9057\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2498 - categorical_accuracy: 0.8890\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2841 - categorical_accuracy: 0.8730\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3557 - categorical_accuracy: 0.7935\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2160 - categorical_accuracy: 0.9202\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2660 - categorical_accuracy: 0.8493\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1929 - categorical_accuracy: 0.9726\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1786 - categorical_accuracy: 0.9811\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1947 - categorical_accuracy: 0.9403\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1513 - categorical_accuracy: 0.9622\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1612 - categorical_accuracy: 0.9665\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1904 - categorical_accuracy: 0.9205\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1497 - categorical_accuracy: 0.9622\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1558 - categorical_accuracy: 0.9884\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1111 - categorical_accuracy: 0.9622\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1385 - categorical_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13821e4f0d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50) #, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef6ee961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:45:16.155670Z",
     "start_time": "2022-03-03T08:45:15.867671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1783 - categorical_accuracy: 0.9762\n",
      "[0.17831891775131226, 0.976190447807312]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1308 - categorical_accuracy: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13077093660831451, 0.9841269850730896]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test))\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2d994",
   "metadata": {},
   "source": [
    " # Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a9c3b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:46:13.297131Z",
     "start_time": "2022-03-03T08:46:07.250686Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان']\n",
      "['برتقان', 'بطيخ']\n",
      "['برتقان', 'بطيخ']\n",
      "['برتقان', 'بطيخ']\n",
      "['برتقان', 'بطيخ']\n",
      "['برتقان', 'بطيخ']\n",
      "['برتقان', 'بطيخ', 'برتقان']\n",
      "['برتقان', 'بطيخ', 'برتقان']\n",
      "['برتقان', 'بطيخ', 'برتقان']\n",
      "['برتقان', 'بطيخ', 'برتقان']\n",
      "['برتقان', 'بطيخ', 'برتقان']\n",
      "['برتقان', 'بطيخ', 'برتقان']\n"
     ]
    }
   ],
   "source": [
    "video = []\n",
    "sentence = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic() as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        frame, results = mediapipe_detection(frame, holistic)\n",
    "        draw_landmarks(frame, results)\n",
    "        \n",
    "        keypoints = extract_keypoints(results)\n",
    "    \n",
    "        video.append(keypoints)\n",
    "        video = video[-30:] # video[:30]\n",
    "        \n",
    "        if len(video) == 30:\n",
    "            res = model.predict(np.expand_dims(video, axis=0))[0]\n",
    " \n",
    "        #################################################\n",
    "        try:\n",
    "            if res[np.argmax(res)] > threshold:\n",
    "                if len(sentence) > 0:\n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "        except:\n",
    "            pass\n",
    "        #################################################\n",
    "            \n",
    "        # FLip frame\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        # Distance\n",
    "        distance = getDistance(frame, results)\n",
    "        cv2.putText(frame, f'Distance {distance}', (530,70),\\\n",
    "                            cv2.FONT_ITALIC, 0.5, (0,0,255), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (0,0), (640,40), (255, 255, 255), -1)\n",
    "        cv2.putText(frame, ' '.join(sentence), (3,30), cv2.FONT_ITALIC, 1, (0,0,0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        print(sentence)\n",
    "        \n",
    "        cv2.imshow('OpenCV', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57a4d92c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T09:28:45.439033Z",
     "start_time": "2022-02-23T09:28:45.400999Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "494bcff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T11:04:21.579599Z",
     "start_time": "2022-02-27T11:04:21.565608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae9736e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T11:01:54.400898Z",
     "start_time": "2022-02-27T11:01:54.380894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أنت\n"
     ]
    }
   ],
   "source": [
    "if sentence[-1] != sentence[-2]:\n",
    "    print(sentence[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da4ee2",
   "metadata": {},
   "source": [
    " # Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fe95f3b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T23:59:26.664419Z",
     "start_time": "2021-11-24T23:59:26.196345Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3a2afb3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T00:01:01.370507Z",
     "start_time": "2021-11-25T00:00:58.285443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 9.9341e-09 - categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('test.h5')\n",
    "loss, accuracy = loaded_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a58014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
